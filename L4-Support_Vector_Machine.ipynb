{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "raising-cincinnati",
   "metadata": {},
   "source": [
    "学习和使用支持向量机\n",
    "\n",
    "- 学习教材6.3、6.4节内容，调试运行相关代码。\n",
    "- 查阅scikit-learn工具包中支持向量机的相关说明，了解分类器函数使用方法。\n",
    "- 完成作业二\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shared-water",
   "metadata": {},
   "source": [
    "# SMO高效优化算法\n",
    "\n",
    "> 书本代码参考仓库[Machine Learning in Action](https://github.com/TeFuirnever/Machine-Learning-in-Action)\n",
    "\n",
    "SMO算法的目标是求出一系列alpha和b，便于计算权重向量并得到分隔超平面。\n",
    "\n",
    "工作原理：选择两个alpha进行优化处理，一旦找到一对合适的alpha，那么就增大一个减少另一个。\n",
    "\n",
    "> “合适”：①alpha须在间隔边界之外；②alpha没有进行过区间化处理或者不在边界上。\n",
    "\n",
    "\n",
    "## 简化版SMO\n",
    "\n",
    "量少，但执行速度慢。跳过SMO的外循环（确定最佳alpha对），遍历每个alpha随机选择另一个。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "reduced-landing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "composite-france",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 6-1 SMO算法中的辅助函数\n",
    "\"\"\"\n",
    "函数说明:读取数据\n",
    "Parameters:\n",
    "    fileName - 文件名\n",
    "Returns:\n",
    "    dataMat - 数据矩阵\n",
    "    labelMat - 数据标签\n",
    "\"\"\"\n",
    "def loadDataSet(fileName):\n",
    "    dataMat = []; labelMat = []\n",
    "    fr = open(fileName)\n",
    "    for line in fr.readlines():                                     #逐行读取，滤除空格等\n",
    "        lineArr = line.strip().split('\\t')\n",
    "        dataMat.append([float(lineArr[0]), float(lineArr[1])])      #添加数据\n",
    "        labelMat.append(float(lineArr[2]))                          #添加标签\n",
    "    return dataMat,labelMat\n",
    "\n",
    "\"\"\"\n",
    "函数说明:随机选择alpha\n",
    "Parameters:\n",
    "    i - alpha\n",
    "    m - alpha参数个数\n",
    "Returns:\n",
    "    j -\n",
    "\"\"\"\n",
    "def selectJrand(i, m):\n",
    "    j = i                                 #选择一个不等于i的j\n",
    "    while (j == i):\n",
    "        j = int(random.uniform(0, m))\n",
    "    return j\n",
    "\n",
    "\"\"\"\n",
    "函数说明:修剪alpha\n",
    "Parameters:\n",
    "    aj - alpha值\n",
    "    H - alpha上限\n",
    "    L - alpha下限\n",
    "Returns:\n",
    "    aj - alpah值\n",
    "\"\"\"\n",
    "def clipAlpha(aj,H,L):\n",
    "    if aj > H:\n",
    "        aj = H\n",
    "    if L > aj:\n",
    "        aj = L\n",
    "    return aj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "round-assistant",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.0, -1.0, 1.0, -1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "dataArr, labelArr = loadDataSet('./data/testSet.txt')\n",
    "print(labelArr[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mature-final",
   "metadata": {},
   "source": [
    "该数据集中类别标签为1，-1。\n",
    "\n",
    "SMO的伪代码大致如下：\n",
    "\n",
    "> * 创建一个alpha向量并将其初始化为0向量\n",
    "> \n",
    "> * 当迭代次数小于最大迭代次数时：\n",
    ">\n",
    ">   * 对数据集中的每个数据向量（外循环）：\n",
    ">\n",
    ">     * 如果该向量可以被优化：\n",
    ">\n",
    ">       * 随机选择另外一个数据向量（内循环）\n",
    ">\n",
    ">       * 同时优化这两个向量\n",
    ">\n",
    ">       * 如果两个向量都不能被优化，退出内循环\n",
    ">\n",
    "> * 如果所有向量都没有被优化，增加迭代数目，继续下一次循环\n",
    "\n",
    "$$\n",
    "fXi = \\sum_{j=1}^N \\alpha_j y_j X_j \\cdot X_i\n",
    "$$\n",
    "\n",
    "步骤1：计算误差Ei=f(x)-y\n",
    "\n",
    "步骤2：计算上下界L和H\n",
    "$$\n",
    "L = \\max{(0,\\alpha_2^{\\text{old}}-\\alpha_1^{\\text{old}})}, \\ \\ \\ H=\\min{(C,C+\\alpha_2^{\\text{old}}-\\alpha_1^{\\text{old}})}\\\\\n",
    "或\\\\\n",
    "L = \\max{(0,\\alpha_2^{\\text{old}}+\\alpha_1^{\\text{old}}-C)}, \\ \\ \\ H=\\min{(C,\\alpha_2^{\\text{old}}+\\alpha_1^{\\text{old}})}\n",
    "$$\n",
    "\n",
    "步骤3：计算eta(η)\n",
    "$$\n",
    "\\eta = K_{11} + K_{22} - 2K_{12} = ||\\phi(x_1)-\\phi(x_2)||^2\n",
    "$$\n",
    "\n",
    "步骤4：更新alpha_j\n",
    "$$\n",
    "\\alpha_2^{\\text{new,unc}} = \\alpha_2^{\\text{old}} + \\dfrac{y_2(E_1-E_2)}{\\eta}\n",
    "$$\n",
    "\n",
    "步骤5：修剪alpha_j\n",
    "$$\n",
    "\\alpha_2^{new} = \\left\\{ \n",
    "\\begin{align}\n",
    "&H,  &\\alpha_2^{\\text{new,unc}}\\gt H \\\\\n",
    "&\\alpha_2^{\\text{new,unc}}, & L \\le\\alpha_2^{\\text{new,unc}}\\le H \\\\\n",
    "&L, &\\alpha_2^{\\text{new,unc}}\\lt L\n",
    "\\end{align}\n",
    "\\right.\n",
    "$$\n",
    "\n",
    "步骤6：更新alpha_i\n",
    "$$\n",
    "\\alpha_1^{\\text{new}} = \\alpha_1^{\\text{old}} + y_1y_2(\\alpha_2^{\\text{old}}-\\alpha_2^{\\text{new}})\n",
    "$$\n",
    "\n",
    "步骤7：更新b_1和b_2\n",
    "$$\n",
    "b_1^{\\text{new}} = b^{\\text{old}} - E_1 - y_1K_{11}(\\alpha_1^{\\text{new}}-\\alpha_1^{\\text{old}}) - y_2K_{21}(\\alpha_2^{\\text{new}}-\\alpha_2^{\\text{old}})\\\\\n",
    "b_2^{\\text{new}} = b^{\\text{old}} - E_2 - y_1K_{12}(\\alpha_1^{\\text{new}}-\\alpha_1^{\\text{old}}) - y_2K_{22}(\\alpha_2^{\\text{new}}-\\alpha_2^{\\text{old}})\\\\           \n",
    "$$\n",
    "\n",
    "步骤8：根据b_1和b_2更新b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "hundred-router",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "函数说明:简化版SMO算法\n",
    "Parameters:\n",
    "    dataMatIn - 数据矩阵\n",
    "    classLabels - 数据标签\n",
    "    C - 松弛变量\n",
    "    toler - 容错率\n",
    "    maxIter - 最大迭代次数\n",
    "Returns:\n",
    "    无\n",
    "\"\"\"\n",
    "def smoSimple(dataMatIn, classLabels, C, toler, maxIter):\n",
    "    #转换为numpy的mat存储\n",
    "    dataMatrix = np.mat(dataMatIn); labelMat = np.mat(classLabels).transpose()\n",
    "    #初始化b参数，统计dataMatrix的维度\n",
    "    b = 0; m,n = np.shape(dataMatrix)\n",
    "    #初始化alpha参数，设为0\n",
    "    alphas = np.mat(np.zeros((m,1)))\n",
    "    #初始化迭代次数\n",
    "    iter_num = 0\n",
    "    #最多迭代matIter次\n",
    "    while (iter_num < maxIter):\n",
    "        alphaPairsChanged = 0\n",
    "        for i in range(m):\n",
    "            #步骤1：计算误差Ei\n",
    "            fXi = float(np.multiply(alphas,labelMat).T*(dataMatrix*dataMatrix[i,:].T)) + b\n",
    "            ##fXi = \\sum_{j=1}^N \\alpha_j y_j X_j \\cdot X_i X:Vector\n",
    "            Ei = fXi - float(labelMat[i])\n",
    "            #优化alpha，更设定一定的容错率。\n",
    "            if ((labelMat[i]*Ei < -toler) and (alphas[i] < C)) or ((labelMat[i]*Ei > toler) and (alphas[i] > 0)):\n",
    "                #随机选择另一个与alpha_i成对优化的alpha_j\n",
    "                j = selectJrand(i,m)\n",
    "                #步骤1：计算误差Ej\n",
    "                fXj = float(np.multiply(alphas,labelMat).T*(dataMatrix*dataMatrix[j,:].T)) + b\n",
    "                Ej = fXj - float(labelMat[j])\n",
    "                #保存更新前的aplpha值，使用深拷贝\n",
    "                alphaIold = alphas[i].copy(); alphaJold = alphas[j].copy();\n",
    "                #步骤2：计算上下界L和H\n",
    "                if (labelMat[i] != labelMat[j]):\n",
    "                    L = max(0, alphas[j] - alphas[i])\n",
    "                    H = min(C, C + alphas[j] - alphas[i])\n",
    "                else:\n",
    "                    L = max(0, alphas[j] + alphas[i] - C)\n",
    "                    H = min(C, alphas[j] + alphas[i])\n",
    "                ## L = \\max{(0,\\alpha_2^{\\text{old}}-\\alpha_1^{\\text{old}})}, \\ \\ \\ H=\\min{(C,C+\\alpha_2^{\\text{old}}-\\alpha_1^{\\text{old}})}\n",
    "                ## L = \\max{(0,\\alpha_2^{\\text{old}}+\\alpha_1^{\\text{old}}-C)}, \\ \\ \\ H=\\min{(C,\\alpha_2^{\\text{old}}+\\alpha_1^{\\text{old}})}\n",
    "                if L==H: print(\"L==H\"); continue\n",
    "                #步骤3：计算eta(η)\n",
    "                eta = 2.0 * dataMatrix[i,:]*dataMatrix[j,:].T - dataMatrix[i,:]*dataMatrix[i,:].T - dataMatrix[j,:]*dataMatrix[j,:].T\n",
    "                ## \\eta = K_{11} + K_{22} - 2K_{12} = ||\\phi(x_1)-\\phi(x_2)||^2\n",
    "                if eta >= 0: print(\"eta>=0\"); continue\n",
    "                #步骤4：更新alpha_j\n",
    "                alphas[j] -= labelMat[j]*(Ei - Ej)/eta\n",
    "                ## \\alpha_2^{\\text{new,unc}} = \\alpha_2^{\\text{old}} + \\dfrac{y_2(E_1-E_2)}{\\eta}\n",
    "                #步骤5：修剪alpha_j\n",
    "                alphas[j] = clipAlpha(alphas[j],H,L)\n",
    "                if (abs(alphas[j] - alphaJold) < 0.00001): print(\"alpha_j变化太小\"); continue\n",
    "                #步骤6：更新alpha_i\n",
    "                alphas[i] += labelMat[j]*labelMat[i]*(alphaJold - alphas[j])\n",
    "                ## \\alpha_1^{\\text{new}} = \\alpha_1^{\\text{old}} + y_1y_2(\\alpha_2^{\\text{old}}-\\alpha_2^{\\text{new}})\n",
    "                #步骤7：更新b_1和b_2\n",
    "                b1 = b - Ei- labelMat[i]*(alphas[i]-alphaIold)*dataMatrix[i,:]*dataMatrix[i,:].T - labelMat[j]*(alphas[j]-alphaJold)*dataMatrix[i,:]*dataMatrix[j,:].T\n",
    "                b2 = b - Ej- labelMat[i]*(alphas[i]-alphaIold)*dataMatrix[i,:]*dataMatrix[j,:].T - labelMat[j]*(alphas[j]-alphaJold)*dataMatrix[j,:]*dataMatrix[j,:].T\n",
    "                ##b_1^{\\text{new}} = b^{\\text{old}} - E_1 - y_1K_{11}(\\alpha_1^{\\text{new}}-\\alpha_1^{\\text{old}}) - y_2K_{21}(\\alpha_2^{\\text{new}}-\\alpha_2^{\\text{old}})\\\\\n",
    "                ##b_2^{\\text{new}} = b^{\\text{old}} - E_2 - y_1K_{12}(\\alpha_1^{\\text{new}}-\\alpha_1^{\\text{old}}) - y_2K_{22}(\\alpha_2^{\\text{new}}-\\alpha_2^{\\text{old}})\\\\\n",
    "                #步骤8：根据b_1和b_2更新b\n",
    "                if (0 < alphas[i]) and (C > alphas[i]): b = b1\n",
    "                elif (0 < alphas[j]) and (C > alphas[j]): b = b2\n",
    "                else: b = (b1 + b2)/2.0\n",
    "                #统计优化次数\n",
    "                alphaPairsChanged += 1\n",
    "                #打印统计信息\n",
    "                print(\"第%d次迭代 样本:%d, alpha优化次数:%d\" % (iter_num,i,alphaPairsChanged))\n",
    "        #更新迭代次数\n",
    "        if (alphaPairsChanged == 0): iter_num += 1\n",
    "        else: iter_num = 0\n",
    "        print(\"迭代次数: %d\" % iter_num)\n",
    "    return b,alphas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hundred-beast",
   "metadata": {},
   "source": [
    "进行简单的测试："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "parental-suspect",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第0次迭代 样本:0, alpha优化次数:1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "第0次迭代 样本:5, alpha优化次数:2\n",
      "L==H\n",
      "L==H\n",
      "L==H\n",
      "第0次迭代 样本:23, alpha优化次数:3\n",
      "第0次迭代 样本:24, alpha优化次数:4\n",
      "第0次迭代 样本:25, alpha优化次数:5\n",
      "第0次迭代 样本:26, alpha优化次数:6\n",
      "alpha_j变化太小\n",
      "第0次迭代 样本:31, alpha优化次数:7\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "第0次迭代 样本:56, alpha优化次数:8\n",
      "L==H\n",
      "alpha_j变化太小\n",
      "L==H\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "L==H\n",
      "alpha_j变化太小\n",
      "迭代次数: 0\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "L==H\n",
      "L==H\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "L==H\n",
      "alpha_j变化太小\n",
      "L==H\n",
      "L==H\n",
      "alpha_j变化太小\n",
      "L==H\n",
      "alpha_j变化太小\n",
      "L==H\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "L==H\n",
      "迭代次数: 1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "第1次迭代 样本:10, alpha优化次数:1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "第1次迭代 样本:29, alpha优化次数:2\n",
      "第1次迭代 样本:54, alpha优化次数:3\n",
      "第1次迭代 样本:55, alpha优化次数:4\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "L==H\n",
      "迭代次数: 0\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "L==H\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "L==H\n",
      "alpha_j变化太小\n",
      "第0次迭代 样本:71, alpha优化次数:1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 0\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "第0次迭代 样本:10, alpha优化次数:1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "第0次迭代 样本:45, alpha优化次数:2\n",
      "第0次迭代 样本:54, alpha优化次数:3\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "L==H\n",
      "迭代次数: 0\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "第0次迭代 样本:5, alpha优化次数:1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "L==H\n",
      "迭代次数: 0\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "第0次迭代 样本:23, alpha优化次数:1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "第0次迭代 样本:55, alpha优化次数:2\n",
      "alpha_j变化太小\n",
      "迭代次数: 0\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "第0次迭代 样本:10, alpha优化次数:1\n",
      "第0次迭代 样本:17, alpha优化次数:2\n",
      "alpha_j变化太小\n",
      "第0次迭代 样本:24, alpha优化次数:3\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 0\n",
      "alpha_j变化太小\n",
      "L==H\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "第0次迭代 样本:54, alpha优化次数:1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 0\n",
      "alpha_j变化太小\n",
      "第0次迭代 样本:1, alpha优化次数:1\n",
      "L==H\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 0\n",
      "L==H\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "第0次迭代 样本:54, alpha优化次数:1\n",
      "第0次迭代 样本:55, alpha优化次数:2\n",
      "第0次迭代 样本:94, alpha优化次数:3\n",
      "alpha_j变化太小\n",
      "迭代次数: 0\n",
      "第0次迭代 样本:0, alpha优化次数:1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "第0次迭代 样本:97, alpha优化次数:2\n",
      "迭代次数: 0\n",
      "alpha_j变化太小\n",
      "L==H\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 1\n",
      "alpha_j变化太小\n",
      "第1次迭代 样本:10, alpha优化次数:1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "L==H\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 0\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "第0次迭代 样本:52, alpha优化次数:1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 0\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "第0次迭代 样本:23, alpha优化次数:1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "第0次迭代 样本:46, alpha优化次数:2\n",
      "alpha_j变化太小\n",
      "第0次迭代 样本:54, alpha优化次数:3\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 0\n",
      "第0次迭代 样本:10, alpha优化次数:1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 0\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 2\n",
      "第2次迭代 样本:8, alpha优化次数:1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "第2次迭代 样本:29, alpha优化次数:2\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 0\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "第1次迭代 样本:55, alpha优化次数:1\n",
      "alpha_j变化太小\n",
      "迭代次数: 0\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "第0次迭代 样本:24, alpha优化次数:1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 0\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "L==H\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "第1次迭代 样本:17, alpha优化次数:1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 0\n",
      "alpha_j变化太小\n",
      "第0次迭代 样本:23, alpha优化次数:1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "第0次迭代 样本:54, alpha优化次数:2\n",
      "第0次迭代 样本:55, alpha优化次数:3\n",
      "alpha_j变化太小\n",
      "迭代次数: 0\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 2\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 3\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "第3次迭代 样本:54, alpha优化次数:1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 0\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 2\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 3\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 4\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 5\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 6\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 7\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 8\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "第8次迭代 样本:29, alpha优化次数:1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 0\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 2\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 3\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 4\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 5\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 6\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 7\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "第7次迭代 样本:55, alpha优化次数:1\n",
      "alpha_j变化太小\n",
      "迭代次数: 0\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "第0次迭代 样本:54, alpha优化次数:1\n",
      "alpha_j变化太小\n",
      "迭代次数: 0\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 2\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 3\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "第3次迭代 样本:29, alpha优化次数:1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 0\n",
      "第0次迭代 样本:17, alpha优化次数:1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 0\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 2\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 3\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "第3次迭代 样本:54, alpha优化次数:1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 0\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 1\n",
      "alpha_j变化太小\n",
      "第1次迭代 样本:23, alpha优化次数:1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 0\n",
      "第0次迭代 样本:17, alpha优化次数:1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 0\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 2\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "第2次迭代 样本:54, alpha优化次数:1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 0\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 2\n",
      "第2次迭代 样本:17, alpha优化次数:1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 0\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 2\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 3\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 4\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 5\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha_j变化太小\n",
      "第6次迭代 样本:29, alpha优化次数:1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 0\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 2\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 3\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 4\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 5\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 6\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 7\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 8\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 9\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 10\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 11\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 12\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 13\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 14\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 15\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 16\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 17\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 18\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 19\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 20\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 21\n",
      "alpha_j变化太小\n",
      "第21次迭代 样本:23, alpha优化次数:1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 0\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 2\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 3\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 4\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "第4次迭代 样本:54, alpha优化次数:1\n",
      "alpha_j变化太小\n",
      "迭代次数: 0\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "第1次迭代 样本:55, alpha优化次数:1\n",
      "迭代次数: 0\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "L==H\n",
      "alpha_j变化太小\n",
      "迭代次数: 1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 2\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 3\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 4\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 5\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "L==H\n",
      "alpha_j变化太小\n",
      "迭代次数: 6\n",
      "第6次迭代 样本:17, alpha优化次数:1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 0\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 2\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 3\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 4\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 5\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 6\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 7\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 8\n",
      "alpha_j变化太小\n",
      "第8次迭代 样本:29, alpha优化次数:1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 0\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "第0次迭代 样本:55, alpha优化次数:1\n",
      "迭代次数: 0\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "第0次迭代 样本:54, alpha优化次数:1\n",
      "迭代次数: 0\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "第1次迭代 样本:52, alpha优化次数:1\n",
      "迭代次数: 0\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 2\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 3\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 4\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 5\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 6\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 7\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 8\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 9\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 10\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 11\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 12\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 13\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 14\n",
      "第14次迭代 样本:17, alpha优化次数:1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 0\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 2\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 3\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 4\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 5\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 6\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 7\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 8\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 9\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 10\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 11\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 12\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 13\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 14\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 15\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 16\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 17\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 18\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 19\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 20\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 21\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 22\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 23\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 24\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 25\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 26\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 27\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 28\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 29\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 30\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 31\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 32\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 33\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 34\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 35\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 36\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 37\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 38\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 39\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 40\n",
      "CPU times: user 3.03 s, sys: 567 ms, total: 3.6 s\n",
      "Wall time: 2.75 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "b, alphas = smoSimple(dataArr, labelArr, 0.6, 0.001, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "gross-modern",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[-3.90043157]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "interesting-doctor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.10104876, 0.26933193, 0.03268721, 0.33769349]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphas[alphas>0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southeast-waters",
   "metadata": {},
   "source": [
    "## 完整Platt SMO\n",
    "\n",
    "简化版SMO中，外层循环是遍历所有样本点作为 $\\alpha_i$ ，内层循环则是随机选择 $\\alpha_j$ 更新这两个 $\\alpha$ 。这样做计算速度较慢，在较大量数据集或维度较高数据集中很可能耗时过多。\n",
    "\n",
    "完整版的Platt SMO的外层循环是遍历所有样本点和遍历非边界点交替进行，遍历所有样本点之后就遍历所有非边界点，遍历非边界点之后如果没有 $\\alpha$ 被更新则重新遍历所有样本点；否则继续遍历非边界点。\n",
    "\n",
    "内循环则不是随机选择，是通过计算最大化步长 $|E_i-E_j|$ 来进行选择，选择使得 $|E_i-E_j|$ 最大的点作为 $\\alpha_j$。\n",
    "\n",
    "简化版和完整版仅在 $\\alpha$ 的选择上有所不同，内部计算和更新方法相同，不再赘述。但是后者的计算效率相对较高。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "constitutional-union",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 6-3 完整版SMO的支持函数\n",
    "\"\"\"\n",
    "数据结构，维护所有需要操作的值\n",
    "Parameters：\n",
    "    dataMatIn - 数据矩阵\n",
    "    classLabels - 数据标签\n",
    "    C - 松弛变量\n",
    "    toler - 容错率\n",
    "\"\"\"\n",
    "class optStruct:\n",
    "    def __init__(self, dataMatIn, classLabels, C, toler):\n",
    "        self.X = dataMatIn                                #数据矩阵\n",
    "        self.labelMat = classLabels                        #数据标签\n",
    "        self.C = C                                         #松弛变量\n",
    "        self.tol = toler                                 #容错率\n",
    "        self.m = np.shape(dataMatIn)[0]                 #数据矩阵行数\n",
    "        self.alphas = np.mat(np.zeros((self.m,1)))         #根据矩阵行数初始化alpha参数为0\n",
    "        self.b = 0                                         #初始化b参数为0\n",
    "        self.eCache = np.mat(np.zeros((self.m,2)))         #根据矩阵行数初始化虎误差缓存，第一列为是否有效的标志位，第二列为实际的误差E的值。\n",
    "\n",
    "\"\"\"\n",
    "读取数据\n",
    "Parameters:\n",
    "    fileName - 文件名\n",
    "Returns:\n",
    "    dataMat - 数据矩阵\n",
    "    labelMat - 数据标签\n",
    "\"\"\"     \n",
    "def loadDataSet(fileName):\n",
    "    dataMat = []; labelMat = []\n",
    "    fr = open(fileName)\n",
    "    for line in fr.readlines():                                     #逐行读取，滤除空格等\n",
    "        lineArr = line.strip().split('\\t')\n",
    "        dataMat.append([float(lineArr[0]), float(lineArr[1])])      #添加数据\n",
    "        labelMat.append(float(lineArr[2]))                          #添加标签\n",
    "    return dataMat,labelMat\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "计算误差\n",
    "Parameters：\n",
    "    oS - 数据结构\n",
    "    k - 标号为k的数据\n",
    "Returns:\n",
    "    Ek - 标号为k的数据误差\n",
    "\"\"\"\n",
    "def calcEk(oS, k):\n",
    "    fXk = float(np.multiply(oS.alphas,oS.labelMat).T*(oS.X*oS.X[k,:].T) + oS.b)\n",
    "    Ek = fXk - float(oS.labelMat[k])\n",
    "    return Ek\n",
    "\n",
    "\"\"\"\n",
    "内循环启发方式2\n",
    "Parameters：\n",
    "    i - 标号为i的数据的索引值\n",
    "    oS - 数据结构\n",
    "    Ei - 标号为i的数据误差\n",
    "Returns:\n",
    "    j, maxK - 标号为j或maxK的数据的索引值\n",
    "    Ej - 标号为j的数据误差\n",
    "\"\"\"\n",
    "def selectJ(i, oS, Ei):\n",
    "    maxK = -1; maxDeltaE = 0; Ej = 0                         #初始化\n",
    "    oS.eCache[i] = [1,Ei]                                      #根据Ei更新误差缓存\n",
    "    validEcacheList = np.nonzero(oS.eCache[:,0].A)[0]        #返回误差不为0的数据的索引值\n",
    "    if (len(validEcacheList)) > 1:                            #有不为0的误差\n",
    "        for k in validEcacheList:                           #遍历,找到最大的Ek\n",
    "            if k == i: continue                             #不计算i,浪费时间\n",
    "            Ek = calcEk(oS, k)                                #计算Ek\n",
    "            deltaE = abs(Ei - Ek)                            #计算|Ei-Ek|\n",
    "            if (deltaE > maxDeltaE):                        #找到maxDeltaE\n",
    "                maxK = k; maxDeltaE = deltaE; Ej = Ek\n",
    "        return maxK, Ej                                        #返回maxK,Ej\n",
    "    else:                                                   #没有不为0的误差\n",
    "        j = selectJrand(i, oS.m)                            #随机选择alpha_j的索引值\n",
    "        Ej = calcEk(oS, j)                                    #计算Ej\n",
    "    return j, Ej                                             #j,Ej\n",
    "\n",
    "\"\"\"\n",
    "计算Ek,并更新误差缓存\n",
    "Parameters：\n",
    "    oS - 数据结构\n",
    "    k - 标号为k的数据的索引值\n",
    "Returns:\n",
    "    无\n",
    "\"\"\"\n",
    "def updateEk(oS, k):\n",
    "    Ek = calcEk(oS, k)                                        #计算Ek\n",
    "    oS.eCache[k] = [1,Ek]                                    #更新误差缓存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "parental-liabilities",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 6-4 完整Platt SMO算法中的优化例程\n",
    "\"\"\"\n",
    "优化的SMO算法\n",
    "Parameters：\n",
    "    i - 标号为i的数据的索引值\n",
    "    oS - 数据结构\n",
    "Returns:\n",
    "    1 - 有任意一对alpha值发生变化\n",
    "    0 - 没有任意一对alpha值发生变化或变化太小\n",
    "\"\"\"\n",
    "def innerL(i, oS):\n",
    "    #步骤1：计算误差Ei\n",
    "    Ei = calcEk(oS, i)\n",
    "    #优化alpha,设定一定的容错率。\n",
    "    if ((oS.labelMat[i] * Ei < -oS.tol) and (oS.alphas[i] < oS.C)) or ((oS.labelMat[i] * Ei > oS.tol) and (oS.alphas[i] > 0)):\n",
    "        #使用内循环启发方式2选择alpha_j,并计算Ej\n",
    "        j,Ej = selectJ(i, oS, Ei)\n",
    "        #保存更新前的aplpha值，使用深拷贝\n",
    "        alphaIold = oS.alphas[i].copy(); alphaJold = oS.alphas[j].copy();\n",
    "        #步骤2：计算上下界L和H\n",
    "        if (oS.labelMat[i] != oS.labelMat[j]):\n",
    "            L = max(0, oS.alphas[j] - oS.alphas[i])\n",
    "            H = min(oS.C, oS.C + oS.alphas[j] - oS.alphas[i])\n",
    "        else:\n",
    "            L = max(0, oS.alphas[j] + oS.alphas[i] - oS.C)\n",
    "            H = min(oS.C, oS.alphas[j] + oS.alphas[i])\n",
    "        if L == H:\n",
    "            print(\"L==H\")\n",
    "            return 0\n",
    "        #步骤3：计算eta\n",
    "        eta = 2.0 * oS.X[i,:] * oS.X[j,:].T - oS.X[i,:] * oS.X[i,:].T - oS.X[j,:] * oS.X[j,:].T\n",
    "        if eta >= 0:\n",
    "            print(\"eta>=0\")\n",
    "            return 0\n",
    "        #步骤4：更新alpha_j\n",
    "        oS.alphas[j] -= oS.labelMat[j] * (Ei - Ej)/eta\n",
    "        #步骤5：修剪alpha_j\n",
    "        oS.alphas[j] = clipAlpha(oS.alphas[j],H,L)\n",
    "        #更新Ej至误差缓存\n",
    "        updateEk(oS, j)\n",
    "        if (abs(oS.alphas[j] - alphaJold) < 0.00001):\n",
    "            print(\"alpha_j变化太小\")\n",
    "            return 0\n",
    "        #步骤6：更新alpha_i\n",
    "        oS.alphas[i] += oS.labelMat[j]*oS.labelMat[i]*(alphaJold - oS.alphas[j])\n",
    "        #更新Ei至误差缓存\n",
    "        updateEk(oS, i)\n",
    "        #步骤7：更新b_1和b_2\n",
    "        b1 = oS.b - Ei- oS.labelMat[i]*(oS.alphas[i]-alphaIold)*oS.X[i,:]*oS.X[i,:].T - oS.labelMat[j]*(oS.alphas[j]-alphaJold)*oS.X[i,:]*oS.X[j,:].T\n",
    "        b2 = oS.b - Ej- oS.labelMat[i]*(oS.alphas[i]-alphaIold)*oS.X[i,:]*oS.X[j,:].T - oS.labelMat[j]*(oS.alphas[j]-alphaJold)*oS.X[j,:]*oS.X[j,:].T\n",
    "        #步骤8：根据b_1和b_2更新b\n",
    "        if (0 < oS.alphas[i]) and (oS.C > oS.alphas[i]): oS.b = b1\n",
    "        elif (0 < oS.alphas[j]) and (oS.C > oS.alphas[j]): oS.b = b2\n",
    "        else: oS.b = (b1 + b2)/2.0\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "empty-fellowship",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "完整的线性SMO算法\n",
    "Parameters：\n",
    "    dataMatIn - 数据矩阵\n",
    "    classLabels - 数据标签\n",
    "    C - 松弛变量\n",
    "    toler - 容错率\n",
    "    maxIter - 最大迭代次数\n",
    "Returns:\n",
    "    oS.b - SMO算法计算的b\n",
    "    oS.alphas - SMO算法计算的alphas\n",
    "\"\"\"\n",
    "def smoP(dataMatIn, classLabels, C, toler, maxIter):\n",
    "    oS = optStruct(np.mat(dataMatIn), np.mat(classLabels).transpose(), C, toler)                    #初始化数据结构\n",
    "    iter = 0                                                                                         #初始化当前迭代次数\n",
    "    entireSet = True; alphaPairsChanged = 0\n",
    "    while (iter < maxIter) and ((alphaPairsChanged > 0) or (entireSet)):                            #遍历整个数据集都alpha也没有更新或者超过最大迭代次数,则退出循环\n",
    "        alphaPairsChanged = 0\n",
    "        if entireSet:                                                                                #遍历整个数据集\n",
    "            for i in range(oS.m):# 对数据集中的所有行\n",
    "                alphaPairsChanged += innerL(i,oS)                                                    #使用优化的SMO算法\n",
    "                print(\"全样本遍历:第%d次迭代 样本:%d, alpha优化次数:%d\" % (iter,i,alphaPairsChanged))\n",
    "            iter += 1\n",
    "        else:                                                                                         #遍历非边界值\n",
    "            nonBoundIs = np.nonzero((oS.alphas.A > 0) * (oS.alphas.A < C))[0]                        #遍历不在边界0和C的alpha\n",
    "            for i in nonBoundIs:\n",
    "                alphaPairsChanged += innerL(i,oS)\n",
    "                print(\"非边界遍历:第%d次迭代 样本:%d, alpha优化次数:%d\" % (iter,i,alphaPairsChanged))\n",
    "            iter += 1\n",
    "        if entireSet:                                                                                #遍历一次后改为非边界遍历\n",
    "            entireSet = False\n",
    "        elif (alphaPairsChanged == 0):                                                                #如果alpha没有更新,计算全样本遍历\n",
    "            entireSet = True\n",
    "        print(\"迭代次数: %d\" % iter)\n",
    "    return oS.b,oS.alphas                                                                             #返回SMO算法计算的b和alphas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "completed-basic",
   "metadata": {},
   "source": [
    "测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "periodic-image",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "全样本遍历:第0次迭代 样本:0, alpha优化次数:1\n",
      "全样本遍历:第0次迭代 样本:1, alpha优化次数:1\n",
      "全样本遍历:第0次迭代 样本:2, alpha优化次数:2\n",
      "全样本遍历:第0次迭代 样本:3, alpha优化次数:3\n",
      "全样本遍历:第0次迭代 样本:4, alpha优化次数:4\n",
      "全样本遍历:第0次迭代 样本:5, alpha优化次数:5\n",
      "全样本遍历:第0次迭代 样本:6, alpha优化次数:5\n",
      "全样本遍历:第0次迭代 样本:7, alpha优化次数:5\n",
      "全样本遍历:第0次迭代 样本:8, alpha优化次数:6\n",
      "全样本遍历:第0次迭代 样本:9, alpha优化次数:6\n",
      "L==H\n",
      "全样本遍历:第0次迭代 样本:10, alpha优化次数:6\n",
      "全样本遍历:第0次迭代 样本:11, alpha优化次数:6\n",
      "全样本遍历:第0次迭代 样本:12, alpha优化次数:6\n",
      "全样本遍历:第0次迭代 样本:13, alpha优化次数:6\n",
      "全样本遍历:第0次迭代 样本:14, alpha优化次数:6\n",
      "全样本遍历:第0次迭代 样本:15, alpha优化次数:7\n",
      "全样本遍历:第0次迭代 样本:16, alpha优化次数:7\n",
      "L==H\n",
      "全样本遍历:第0次迭代 样本:17, alpha优化次数:7\n",
      "全样本遍历:第0次迭代 样本:18, alpha优化次数:8\n",
      "全样本遍历:第0次迭代 样本:19, alpha优化次数:8\n",
      "全样本遍历:第0次迭代 样本:20, alpha优化次数:8\n",
      "全样本遍历:第0次迭代 样本:21, alpha优化次数:8\n",
      "全样本遍历:第0次迭代 样本:22, alpha优化次数:8\n",
      "L==H\n",
      "全样本遍历:第0次迭代 样本:23, alpha优化次数:8\n",
      "全样本遍历:第0次迭代 样本:24, alpha优化次数:8\n",
      "alpha_j变化太小\n",
      "全样本遍历:第0次迭代 样本:25, alpha优化次数:8\n",
      "L==H\n",
      "全样本遍历:第0次迭代 样本:26, alpha优化次数:8\n",
      "全样本遍历:第0次迭代 样本:27, alpha优化次数:8\n",
      "全样本遍历:第0次迭代 样本:28, alpha优化次数:8\n",
      "L==H\n",
      "全样本遍历:第0次迭代 样本:29, alpha优化次数:8\n",
      "全样本遍历:第0次迭代 样本:30, alpha优化次数:8\n",
      "全样本遍历:第0次迭代 样本:31, alpha优化次数:8\n",
      "全样本遍历:第0次迭代 样本:32, alpha优化次数:8\n",
      "全样本遍历:第0次迭代 样本:33, alpha优化次数:8\n",
      "全样本遍历:第0次迭代 样本:34, alpha优化次数:8\n",
      "全样本遍历:第0次迭代 样本:35, alpha优化次数:8\n",
      "全样本遍历:第0次迭代 样本:36, alpha优化次数:8\n",
      "全样本遍历:第0次迭代 样本:37, alpha优化次数:8\n",
      "全样本遍历:第0次迭代 样本:38, alpha优化次数:8\n",
      "全样本遍历:第0次迭代 样本:39, alpha优化次数:8\n",
      "全样本遍历:第0次迭代 样本:40, alpha优化次数:8\n",
      "全样本遍历:第0次迭代 样本:41, alpha优化次数:8\n",
      "全样本遍历:第0次迭代 样本:42, alpha优化次数:8\n",
      "全样本遍历:第0次迭代 样本:43, alpha优化次数:8\n",
      "全样本遍历:第0次迭代 样本:44, alpha优化次数:8\n",
      "alpha_j变化太小\n",
      "全样本遍历:第0次迭代 样本:45, alpha优化次数:8\n",
      "L==H\n",
      "全样本遍历:第0次迭代 样本:46, alpha优化次数:8\n",
      "全样本遍历:第0次迭代 样本:47, alpha优化次数:8\n",
      "全样本遍历:第0次迭代 样本:48, alpha优化次数:8\n",
      "全样本遍历:第0次迭代 样本:49, alpha优化次数:8\n",
      "全样本遍历:第0次迭代 样本:50, alpha优化次数:8\n",
      "全样本遍历:第0次迭代 样本:51, alpha优化次数:8\n",
      "L==H\n",
      "全样本遍历:第0次迭代 样本:52, alpha优化次数:8\n",
      "全样本遍历:第0次迭代 样本:53, alpha优化次数:8\n",
      "L==H\n",
      "全样本遍历:第0次迭代 样本:54, alpha优化次数:8\n",
      "L==H\n",
      "全样本遍历:第0次迭代 样本:55, alpha优化次数:8\n",
      "全样本遍历:第0次迭代 样本:56, alpha优化次数:8\n",
      "全样本遍历:第0次迭代 样本:57, alpha优化次数:9\n",
      "全样本遍历:第0次迭代 样本:58, alpha优化次数:9\n",
      "全样本遍历:第0次迭代 样本:59, alpha优化次数:9\n",
      "alpha_j变化太小\n",
      "全样本遍历:第0次迭代 样本:60, alpha优化次数:9\n",
      "全样本遍历:第0次迭代 样本:61, alpha优化次数:9\n",
      "全样本遍历:第0次迭代 样本:62, alpha优化次数:9\n",
      "alpha_j变化太小\n",
      "全样本遍历:第0次迭代 样本:63, alpha优化次数:9\n",
      "全样本遍历:第0次迭代 样本:64, alpha优化次数:9\n",
      "alpha_j变化太小\n",
      "全样本遍历:第0次迭代 样本:65, alpha优化次数:9\n",
      "alpha_j变化太小\n",
      "全样本遍历:第0次迭代 样本:66, alpha优化次数:9\n",
      "全样本遍历:第0次迭代 样本:67, alpha优化次数:9\n",
      "全样本遍历:第0次迭代 样本:68, alpha优化次数:9\n",
      "全样本遍历:第0次迭代 样本:69, alpha优化次数:9\n",
      "alpha_j变化太小\n",
      "全样本遍历:第0次迭代 样本:70, alpha优化次数:9\n",
      "全样本遍历:第0次迭代 样本:71, alpha优化次数:9\n",
      "全样本遍历:第0次迭代 样本:72, alpha优化次数:9\n",
      "alpha_j变化太小\n",
      "全样本遍历:第0次迭代 样本:73, alpha优化次数:9\n",
      "alpha_j变化太小\n",
      "全样本遍历:第0次迭代 样本:74, alpha优化次数:9\n",
      "全样本遍历:第0次迭代 样本:75, alpha优化次数:9\n",
      "alpha_j变化太小\n",
      "全样本遍历:第0次迭代 样本:76, alpha优化次数:9\n",
      "全样本遍历:第0次迭代 样本:77, alpha优化次数:9\n",
      "全样本遍历:第0次迭代 样本:78, alpha优化次数:9\n",
      "全样本遍历:第0次迭代 样本:79, alpha优化次数:9\n",
      "全样本遍历:第0次迭代 样本:80, alpha优化次数:9\n",
      "全样本遍历:第0次迭代 样本:81, alpha优化次数:9\n",
      "全样本遍历:第0次迭代 样本:82, alpha优化次数:9\n",
      "全样本遍历:第0次迭代 样本:83, alpha优化次数:9\n",
      "alpha_j变化太小\n",
      "全样本遍历:第0次迭代 样本:84, alpha优化次数:9\n",
      "alpha_j变化太小\n",
      "全样本遍历:第0次迭代 样本:85, alpha优化次数:9\n",
      "alpha_j变化太小\n",
      "全样本遍历:第0次迭代 样本:86, alpha优化次数:9\n",
      "alpha_j变化太小\n",
      "全样本遍历:第0次迭代 样本:87, alpha优化次数:9\n",
      "全样本遍历:第0次迭代 样本:88, alpha优化次数:9\n",
      "全样本遍历:第0次迭代 样本:89, alpha优化次数:9\n",
      "全样本遍历:第0次迭代 样本:90, alpha优化次数:9\n",
      "全样本遍历:第0次迭代 样本:91, alpha优化次数:9\n",
      "全样本遍历:第0次迭代 样本:92, alpha优化次数:9\n",
      "全样本遍历:第0次迭代 样本:93, alpha优化次数:9\n",
      "全样本遍历:第0次迭代 样本:94, alpha优化次数:10\n",
      "全样本遍历:第0次迭代 样本:95, alpha优化次数:10\n",
      "全样本遍历:第0次迭代 样本:96, alpha优化次数:10\n",
      "alpha_j变化太小\n",
      "全样本遍历:第0次迭代 样本:97, alpha优化次数:10\n",
      "全样本遍历:第0次迭代 样本:98, alpha优化次数:10\n",
      "全样本遍历:第0次迭代 样本:99, alpha优化次数:10\n",
      "迭代次数: 1\n",
      "alpha_j变化太小\n",
      "非边界遍历:第1次迭代 样本:0, alpha优化次数:0\n",
      "alpha_j变化太小\n",
      "非边界遍历:第1次迭代 样本:4, alpha优化次数:0\n",
      "alpha_j变化太小\n",
      "非边界遍历:第1次迭代 样本:5, alpha优化次数:0\n",
      "alpha_j变化太小\n",
      "非边界遍历:第1次迭代 样本:8, alpha优化次数:0\n",
      "alpha_j变化太小\n",
      "非边界遍历:第1次迭代 样本:15, alpha优化次数:0\n",
      "alpha_j变化太小\n",
      "非边界遍历:第1次迭代 样本:17, alpha优化次数:0\n",
      "alpha_j变化太小\n",
      "非边界遍历:第1次迭代 样本:18, alpha优化次数:0\n",
      "非边界遍历:第1次迭代 样本:55, alpha优化次数:0\n",
      "非边界遍历:第1次迭代 样本:94, alpha优化次数:0\n",
      "迭代次数: 2\n",
      "alpha_j变化太小\n",
      "全样本遍历:第2次迭代 样本:0, alpha优化次数:0\n",
      "全样本遍历:第2次迭代 样本:1, alpha优化次数:0\n",
      "全样本遍历:第2次迭代 样本:2, alpha优化次数:0\n",
      "全样本遍历:第2次迭代 样本:3, alpha优化次数:0\n",
      "alpha_j变化太小\n",
      "全样本遍历:第2次迭代 样本:4, alpha优化次数:0\n",
      "alpha_j变化太小\n",
      "全样本遍历:第2次迭代 样本:5, alpha优化次数:0\n",
      "全样本遍历:第2次迭代 样本:6, alpha优化次数:0\n",
      "全样本遍历:第2次迭代 样本:7, alpha优化次数:0\n",
      "alpha_j变化太小\n",
      "全样本遍历:第2次迭代 样本:8, alpha优化次数:0\n",
      "全样本遍历:第2次迭代 样本:9, alpha优化次数:0\n",
      "alpha_j变化太小\n",
      "全样本遍历:第2次迭代 样本:10, alpha优化次数:0\n",
      "全样本遍历:第2次迭代 样本:11, alpha优化次数:0\n",
      "全样本遍历:第2次迭代 样本:12, alpha优化次数:0\n",
      "全样本遍历:第2次迭代 样本:13, alpha优化次数:0\n",
      "全样本遍历:第2次迭代 样本:14, alpha优化次数:0\n",
      "alpha_j变化太小\n",
      "全样本遍历:第2次迭代 样本:15, alpha优化次数:0\n",
      "全样本遍历:第2次迭代 样本:16, alpha优化次数:0\n",
      "alpha_j变化太小\n",
      "全样本遍历:第2次迭代 样本:17, alpha优化次数:0\n",
      "alpha_j变化太小\n",
      "全样本遍历:第2次迭代 样本:18, alpha优化次数:0\n",
      "全样本遍历:第2次迭代 样本:19, alpha优化次数:0\n",
      "全样本遍历:第2次迭代 样本:20, alpha优化次数:0\n",
      "全样本遍历:第2次迭代 样本:21, alpha优化次数:0\n",
      "全样本遍历:第2次迭代 样本:22, alpha优化次数:0\n",
      "L==H\n",
      "全样本遍历:第2次迭代 样本:23, alpha优化次数:0\n",
      "alpha_j变化太小\n",
      "全样本遍历:第2次迭代 样本:24, alpha优化次数:0\n",
      "全样本遍历:第2次迭代 样本:25, alpha优化次数:0\n",
      "全样本遍历:第2次迭代 样本:26, alpha优化次数:0\n",
      "全样本遍历:第2次迭代 样本:27, alpha优化次数:0\n",
      "全样本遍历:第2次迭代 样本:28, alpha优化次数:0\n",
      "L==H\n",
      "全样本遍历:第2次迭代 样本:29, alpha优化次数:0\n",
      "alpha_j变化太小\n",
      "全样本遍历:第2次迭代 样本:30, alpha优化次数:0\n",
      "全样本遍历:第2次迭代 样本:31, alpha优化次数:0\n",
      "全样本遍历:第2次迭代 样本:32, alpha优化次数:0\n",
      "全样本遍历:第2次迭代 样本:33, alpha优化次数:0\n",
      "全样本遍历:第2次迭代 样本:34, alpha优化次数:0\n",
      "全样本遍历:第2次迭代 样本:35, alpha优化次数:0\n",
      "全样本遍历:第2次迭代 样本:36, alpha优化次数:0\n",
      "全样本遍历:第2次迭代 样本:37, alpha优化次数:0\n",
      "全样本遍历:第2次迭代 样本:38, alpha优化次数:0\n",
      "全样本遍历:第2次迭代 样本:39, alpha优化次数:0\n",
      "全样本遍历:第2次迭代 样本:40, alpha优化次数:0\n",
      "全样本遍历:第2次迭代 样本:41, alpha优化次数:0\n",
      "全样本遍历:第2次迭代 样本:42, alpha优化次数:0\n",
      "全样本遍历:第2次迭代 样本:43, alpha优化次数:0\n",
      "全样本遍历:第2次迭代 样本:44, alpha优化次数:0\n",
      "全样本遍历:第2次迭代 样本:45, alpha优化次数:0\n",
      "全样本遍历:第2次迭代 样本:46, alpha优化次数:0\n",
      "全样本遍历:第2次迭代 样本:47, alpha优化次数:0\n",
      "全样本遍历:第2次迭代 样本:48, alpha优化次数:0\n",
      "全样本遍历:第2次迭代 样本:49, alpha优化次数:0\n",
      "全样本遍历:第2次迭代 样本:50, alpha优化次数:0\n",
      "全样本遍历:第2次迭代 样本:51, alpha优化次数:0\n",
      "L==H\n",
      "全样本遍历:第2次迭代 样本:52, alpha优化次数:0\n",
      "全样本遍历:第2次迭代 样本:53, alpha优化次数:0\n",
      "L==H\n",
      "全样本遍历:第2次迭代 样本:54, alpha优化次数:0\n",
      "全样本遍历:第2次迭代 样本:55, alpha优化次数:0\n",
      "全样本遍历:第2次迭代 样本:56, alpha优化次数:0\n",
      "全样本遍历:第2次迭代 样本:57, alpha优化次数:0\n",
      "全样本遍历:第2次迭代 样本:58, alpha优化次数:0\n",
      "全样本遍历:第2次迭代 样本:59, alpha优化次数:0\n",
      "全样本遍历:第2次迭代 样本:60, alpha优化次数:0\n",
      "全样本遍历:第2次迭代 样本:61, alpha优化次数:0\n",
      "全样本遍历:第2次迭代 样本:62, alpha优化次数:0\n",
      "全样本遍历:第2次迭代 样本:63, alpha优化次数:0\n",
      "全样本遍历:第2次迭代 样本:64, alpha优化次数:0\n",
      "全样本遍历:第2次迭代 样本:65, alpha优化次数:0\n",
      "全样本遍历:第2次迭代 样本:66, alpha优化次数:0\n",
      "全样本遍历:第2次迭代 样本:67, alpha优化次数:0\n",
      "全样本遍历:第2次迭代 样本:68, alpha优化次数:0\n",
      "全样本遍历:第2次迭代 样本:69, alpha优化次数:0\n",
      "全样本遍历:第2次迭代 样本:70, alpha优化次数:0\n",
      "全样本遍历:第2次迭代 样本:71, alpha优化次数:0\n",
      "全样本遍历:第2次迭代 样本:72, alpha优化次数:0\n",
      "全样本遍历:第2次迭代 样本:73, alpha优化次数:0\n",
      "全样本遍历:第2次迭代 样本:74, alpha优化次数:0\n",
      "全样本遍历:第2次迭代 样本:75, alpha优化次数:0\n",
      "全样本遍历:第2次迭代 样本:76, alpha优化次数:0\n",
      "全样本遍历:第2次迭代 样本:77, alpha优化次数:0\n",
      "全样本遍历:第2次迭代 样本:78, alpha优化次数:0\n",
      "全样本遍历:第2次迭代 样本:79, alpha优化次数:0\n",
      "全样本遍历:第2次迭代 样本:80, alpha优化次数:0\n",
      "全样本遍历:第2次迭代 样本:81, alpha优化次数:0\n",
      "全样本遍历:第2次迭代 样本:82, alpha优化次数:0\n",
      "全样本遍历:第2次迭代 样本:83, alpha优化次数:0\n",
      "全样本遍历:第2次迭代 样本:84, alpha优化次数:0\n",
      "全样本遍历:第2次迭代 样本:85, alpha优化次数:0\n",
      "全样本遍历:第2次迭代 样本:86, alpha优化次数:0\n",
      "全样本遍历:第2次迭代 样本:87, alpha优化次数:0\n",
      "全样本遍历:第2次迭代 样本:88, alpha优化次数:0\n",
      "全样本遍历:第2次迭代 样本:89, alpha优化次数:0\n",
      "全样本遍历:第2次迭代 样本:90, alpha优化次数:0\n",
      "全样本遍历:第2次迭代 样本:91, alpha优化次数:0\n",
      "全样本遍历:第2次迭代 样本:92, alpha优化次数:0\n",
      "全样本遍历:第2次迭代 样本:93, alpha优化次数:0\n",
      "全样本遍历:第2次迭代 样本:94, alpha优化次数:0\n",
      "全样本遍历:第2次迭代 样本:95, alpha优化次数:0\n",
      "全样本遍历:第2次迭代 样本:96, alpha优化次数:0\n",
      "alpha_j变化太小\n",
      "全样本遍历:第2次迭代 样本:97, alpha优化次数:0\n",
      "全样本遍历:第2次迭代 样本:98, alpha优化次数:0\n",
      "全样本遍历:第2次迭代 样本:99, alpha优化次数:0\n",
      "迭代次数: 3\n",
      "CPU times: user 152 ms, sys: 52.8 ms, total: 205 ms\n",
      "Wall time: 149 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dataArr, labelArr = loadDataSet('./data/testSet.txt')\n",
    "b, alphas = smoP(dataArr, labelArr, 0.6, 0.001, 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opposite-tanzania",
   "metadata": {},
   "source": [
    "用时方面，在相同配置的主机上，时间从7秒下降到了不到0.3秒。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "russian-snake",
   "metadata": {},
   "source": [
    "利用计算得到的alpha值，可以计算w用于构建超平面。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "incorporate-friday",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcWs(alphas, dataArr, classLabels):\n",
    "    X = np.mat(dataArr); labelMat = np.mat(classLabels).transpose()\n",
    "    m,n = X.shape\n",
    "    w = np.zeros((n,1))\n",
    "    for i in range(m):\n",
    "        w += np.multiply(alphas[i]*labelMat[i],X[i,:].T)\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "included-romania",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.65263178],\n",
       "       [-0.17581327]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ws = calcWs(alphas,dataArr,labelArr)\n",
    "ws"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mental-opinion",
   "metadata": {},
   "source": [
    "分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "simple-somerset",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.93044397]]\n"
     ]
    }
   ],
   "source": [
    "datMat = np.mat(dataArr)\n",
    "print(datMat[0]*np.mat(ws)+b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "returning-posting",
   "metadata": {},
   "source": [
    "若该值大于0，其属于1类；若该值小于0，属于-1类，这里得到的分类结果是-1，我们验证一下是不是一样的："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "brutal-assurance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelArr[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aquatic-viewer",
   "metadata": {},
   "source": [
    "# SVM in scikit-learn\n",
    "\n",
    "查阅scikit-learn工具包中支持向量机的相关说明，了解分类器函数使用方法。\n",
    "\n",
    "参考这一篇进行学习：[机器学习笔记3-sklearn支持向量机](https://www.jianshu.com/p/a9f9954355b3?utm_campaign=maleskine&utm_content=note&utm_medium=seo_notes&utm_source=recommendation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legitimate-clock",
   "metadata": {},
   "source": [
    "调包当然是非常简单的拉~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "demographic-patrick",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "预测样例：\n",
      "[ 1. -1. -1. -1. -1.]\n",
      "[1.0, -1.0, -1.0, -1.0, -1.0]\n",
      "Train Score: 1.000; Test Score 1.000.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataArr, labelArr, test_size = 0.2, random_state = 100,stratify=labelArr)\n",
    "\n",
    "clf = SVC()\n",
    "clf.fit(X_train, y_train) \n",
    "print('预测样例：')\n",
    "print(clf.predict(np.array(X_test[0:5])))\n",
    "print(y_test[0:5])\n",
    "train_score = clf.score(X_train,y_train)\n",
    "test_score  = clf.score(X_test,y_test)\n",
    "\n",
    "print(\"Train Score: %.3f; Test Score %.3f.\" % (train_score,test_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proved-affairs",
   "metadata": {},
   "source": [
    "好屌，难道是因为是二分类，或者这个样本集很好分吗？什么参数都没有调，准确率达到了100\\%。\n",
    "\n",
    "因为准确率过高，所以后续对SVM的优化需要基于新的数据集，否则无法评判优化的效果。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greater-craft",
   "metadata": {},
   "source": [
    "官方源码：\n",
    "\n",
    "```Python\n",
    "sklearn.svm.SVC(C=1.0, kernel='rbf', degree=3, gamma='auto', coef0=0.0, shrinking=True, \n",
    "                probability=False, tol=0.001, cache_size=200, class_weight=None, \n",
    "                verbose=False, max_iter=-1, decision_function_shape='ovr', \n",
    "                random_state=None)\n",
    "```\n",
    "\n",
    "参考官方源码给出的参数，可以对其进行一定的优化，主要调节的参数有：C、kernel、degree、gamma、coef0。\n",
    "\n",
    "* C：C-SVC的惩罚参数C,默认值是1.0\n",
    "> C越大，相当于惩罚松弛变量，希望松弛变量接近0，即对误分类的惩罚增大，趋向于对训练集全分对的情况，这样对训练集测试时准确率很高，但泛化能力弱。C值小，对误分类的惩罚减小，允许容错，将他们当成噪声点，泛化能力较强。\n",
    "\n",
    "* kernel ：核函数，默认是rbf，可以是`linear`, `poly`, `rbf`, `sigmoid`\n",
    "> 线性：$\\kappa(\\boldsymbol{x}_i,\\boldsymbol{x}_j)=\\boldsymbol{x}_i^T\\boldsymbol{x}_j$ \n",
    ">\n",
    "> 多项式： $\\kappa(\\boldsymbol{x}_i,\\boldsymbol{x}_j)=(\\boldsymbol{x}_i^T\\boldsymbol{x}_j)^d$\n",
    ">\n",
    "> RBF函数/高斯核函数： $\\kappa(\\boldsymbol{x}_i,\\boldsymbol{x}_j)=\\exp\\left(-\\dfrac{||\\boldsymbol{x}_i-\\boldsymbol{x}_j||^2}{2\\sigma^2}\\right)$\n",
    ">\n",
    "> sigmoid：$\\kappa(\\boldsymbol{x}_i,\\boldsymbol{x}_j)=\\tanh{(\\beta\\boldsymbol{x}_i^T\\boldsymbol{x}_j+\\theta)}$ \n",
    "\n",
    "* degree ：多项式poly函数的维度，默认是3，选择其他核函数时会被忽略。\n",
    "\n",
    "* gamma ： `rbf`,`poly` 和`sigmoid`的核函数参数。默认是`auto`，则会选择1/n_features\n",
    "\n",
    "* coef0 ：核函数的常数项。对于`poly`和 `sigmoid`有用。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recorded-angola",
   "metadata": {},
   "source": [
    "# 作业二：\n",
    "已知正例点 $x_1=(1,2)^T$ , $x_2=(2,3)^T$ , $x_3=(3,3)^T$，负例点 $x_4=(2,1)^T$ , $x_5=(3,2)^T$ ,试求最大间隔分离超平面和分类决策函数，并在图上画出分离超平面，间隔边界以及支持向量。\n",
    "\n",
    "(统计学习方法第七章课后习题2）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clinical-priest",
   "metadata": {},
   "source": [
    "**解**\n",
    "\n",
    "参考最大间隔算法，根据训练数据集构造约束最优化问题\n",
    "\n",
    "$$\n",
    "\\min\\frac{1}{2}(w_1^2+w_2^2)\\\\\n",
    "s.t. \\left\\{\n",
    "\\begin{align} \n",
    "w_1+2w_2+b&\\ge 1 \\tag{1}\\\\\n",
    "2w_1+3w_2+b&\\ge 1 \\tag{2}\\\\\n",
    "3w_1+3w_2+b&\\ge 1 \\tag{3}\\\\\n",
    "-2w_1-w_2-b&\\ge 1 \\tag{4}\\\\\n",
    "-3w_1-2w_2-b&\\ge 1 \\tag{5}\n",
    "\\end{align}\n",
    "\\right.\n",
    "$$\n",
    "\n",
    "求得此最优化问题的解$w_1=-1,\\ w_2=2,\\ b=-2$。于是最大间隔分离超平面为\n",
    "$$\n",
    "-x^{(1)}+2x^{(2)}-2=0\n",
    "$$\n",
    "支持向量 $x_1=(1,2)^T$ , $x_3=(3,3)^T$ , $x_5=(3,2)^T$. \n",
    "分类决策函数\n",
    "$$\n",
    "f(x)=\\text{sign}(-x^{(1)}+2x^{(2)}-2)\n",
    "$$\n",
    "\n",
    "<img src=\"https://downloads.mariozzj.cn/img/picgo/1616823918946.jpg\" style=\"zoom:10%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suspended-outside",
   "metadata": {},
   "source": [
    "用程序进行同等的求解验证："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "spanish-steel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.  2.]]\n",
      "[-2.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "x=[[1, 2], [2, 3], [3, 3], [2, 1], [3, 2]]\n",
    "y=[1, 1, 1, -1, -1]\n",
    "clf = svm.SVC(kernel='linear',C=10000)\n",
    "clf.fit(x, y)\n",
    "print(clf.coef_)\n",
    "print(clf.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "portable-virginia",
   "metadata": {},
   "source": [
    "得到的解相同，接下来可以进行一定的可视化："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "medieval-banner",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "plt.scatter([i[0] for i in x], [i[1] for i in x], c=y)\n",
    "xaxis = np.linspace(0, 3.5)\n",
    "w = clf.coef_[0]\n",
    "a = -w[0] / w[1]\n",
    "y_sep = a * xaxis - (clf.intercept_[0]) / w[1]\n",
    "b = clf.support_vectors_[0]\n",
    "yy_down = a * xaxis + (b[1] - a * b[0])\n",
    "b = clf.support_vectors_[-1]\n",
    "yy_up = a * xaxis + (b[1] - a * b[0])\n",
    "plt.plot(xaxis, y_sep, 'k-')\n",
    "plt.plot(xaxis, yy_down, 'k--')\n",
    "plt.plot(xaxis, yy_up, 'k--')\n",
    "plt.scatter (clf.support_vectors_[:, 0], clf.support_vectors_[:, 1], s=150, facecolors='none', edgecolors='k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "together-wyoming",
   "metadata": {},
   "source": [
    "# + 另一种SMO\n",
    "\n",
    "另一种参考统计学习方法上的思路，\n",
    "\n",
    "外层循环选择**违背KKT条件最严重**的 $\\alpha$ 作为 $\\alpha_i$，首先遍历间隔边界上的点（ $0 \\lt \\alpha_i \\lt C$ ），如果这些点都满足KKT条件，则遍历所有样本点。\n",
    "\n",
    "内层循环选择启发式方法选择：\n",
    "\n",
    "* 如果 $E_i$ 为正，选择最小的 $E$ 作为 $E_j$；如果 $E_i$ 为负，选择最大的 $E$ 作为 $E_j$。（总之使步长最大）\n",
    "* 如果上一步都不能使目标函数有足够的下降，则遍历间隔边界上的支持向量点，依次将其作为 $\\alpha_j$ 使用。\n",
    "* 如果都不能使目标函数有足够的下降，则遍历训练集的所有向量点，依次将其作为 $\\alpha_j$ 使用。\n",
    "* 如果所有点都不能使目标函数有足够的下降，则放弃当前 $\\alpha_i$ ，通过外层循环生成新的 $\\alpha_i$ 。\n",
    "\n",
    "\n",
    "参考[fengdu78/lihang-code](https://github.com/fengdu78/lihang-code)的实现代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "imported-aside",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVM:\n",
    "    def __init__(self, max_iter=100, kernel='linear'):\n",
    "        self.max_iter = max_iter\n",
    "        self._kernel = kernel\n",
    "\n",
    "    def init_args(self, features, labels):\n",
    "        self.m, self.n = features.shape\n",
    "        self.X = features\n",
    "        self.Y = labels\n",
    "        self.b = 0.0\n",
    "\n",
    "        # 将Ei保存在一个列表里\n",
    "        self.alpha = np.ones(self.m)\n",
    "        self.E = [self._E(i) for i in range(self.m)]\n",
    "        # 松弛变量\n",
    "        self.C = 1.0\n",
    "\n",
    "    def _KKT(self, i):\n",
    "        y_g = self._g(i) * self.Y[i]\n",
    "        if self.alpha[i] == 0:\n",
    "            return y_g >= 1\n",
    "        elif 0 < self.alpha[i] < self.C:\n",
    "            return y_g == 1\n",
    "        else:\n",
    "            return y_g <= 1\n",
    "\n",
    "    # g(x)预测值，输入xi（X[i]）\n",
    "    def _g(self, i):\n",
    "        r = self.b\n",
    "        for j in range(self.m):\n",
    "            r += self.alpha[j] * self.Y[j] * self.kernel(self.X[i], self.X[j])\n",
    "        return r\n",
    "\n",
    "    # 核函数\n",
    "    def kernel(self, x1, x2):\n",
    "        if self._kernel == 'linear':\n",
    "            return sum([x1[k] * x2[k] for k in range(self.n)])\n",
    "        elif self._kernel == 'poly':\n",
    "            return (sum([x1[k] * x2[k] for k in range(self.n)]) + 1)**2\n",
    "\n",
    "        return 0\n",
    "\n",
    "    # E（x）为g(x)对输入x的预测值和y的差\n",
    "    def _E(self, i):\n",
    "        return self._g(i) - self.Y[i]\n",
    "\n",
    "    def _init_alpha(self):\n",
    "        # 外层循环首先遍历所有满足0<a<C的样本点，检验是否满足KKT\n",
    "        index_list = [i for i in range(self.m) if 0 < self.alpha[i] < self.C]\n",
    "        # 否则遍历整个训练集\n",
    "        non_satisfy_list = [i for i in range(self.m) if i not in index_list]\n",
    "        index_list.extend(non_satisfy_list)\n",
    "\n",
    "        for i in index_list:\n",
    "            if self._KKT(i):\n",
    "                continue\n",
    "\n",
    "            E1 = self.E[i]\n",
    "            # 如果E2是+，选择最小的；如果E2是负的，选择最大的\n",
    "            if E1 >= 0:\n",
    "                j = min(range(self.m), key=lambda x: self.E[x])\n",
    "            else:\n",
    "                j = max(range(self.m), key=lambda x: self.E[x])\n",
    "            return i, j\n",
    "\n",
    "    def _compare(self, _alpha, L, H):\n",
    "        if _alpha > H:\n",
    "            return H\n",
    "        elif _alpha < L:\n",
    "            return L\n",
    "        else:\n",
    "            return _alpha\n",
    "\n",
    "    def fit(self, features, labels):\n",
    "        self.init_args(features, labels)\n",
    "\n",
    "        for t in range(self.max_iter):\n",
    "            # train\n",
    "            i1, i2 = self._init_alpha()\n",
    "\n",
    "            # 边界\n",
    "            if self.Y[i1] == self.Y[i2]:\n",
    "                L = max(0, self.alpha[i1] + self.alpha[i2] - self.C)\n",
    "                H = min(self.C, self.alpha[i1] + self.alpha[i2])\n",
    "            else:\n",
    "                L = max(0, self.alpha[i2] - self.alpha[i1])\n",
    "                H = min(self.C, self.C + self.alpha[i2] - self.alpha[i1])\n",
    "\n",
    "            E1 = self.E[i1]\n",
    "            E2 = self.E[i2]\n",
    "            # eta=K11+K22-2K12\n",
    "            eta = self.kernel(self.X[i1], self.X[i1]) + self.kernel(\n",
    "                self.X[i2],\n",
    "                self.X[i2]) - 2 * self.kernel(self.X[i1], self.X[i2])\n",
    "            if eta <= 0:\n",
    "                # print('eta <= 0')\n",
    "                continue\n",
    "\n",
    "            alpha2_new_unc = self.alpha[i2] + self.Y[i2] * (\n",
    "                E1 - E2) / eta  #此处有修改，根据书上应该是E1 - E2，书上130-131页\n",
    "            alpha2_new = self._compare(alpha2_new_unc, L, H)\n",
    "\n",
    "            alpha1_new = self.alpha[i1] + self.Y[i1] * self.Y[i2] * (\n",
    "                self.alpha[i2] - alpha2_new)\n",
    "\n",
    "            b1_new = -E1 - self.Y[i1] * self.kernel(self.X[i1], self.X[i1]) * (\n",
    "                alpha1_new - self.alpha[i1]) - self.Y[i2] * self.kernel(\n",
    "                    self.X[i2],\n",
    "                    self.X[i1]) * (alpha2_new - self.alpha[i2]) + self.b\n",
    "            b2_new = -E2 - self.Y[i1] * self.kernel(self.X[i1], self.X[i2]) * (\n",
    "                alpha1_new - self.alpha[i1]) - self.Y[i2] * self.kernel(\n",
    "                    self.X[i2],\n",
    "                    self.X[i2]) * (alpha2_new - self.alpha[i2]) + self.b\n",
    "\n",
    "            if 0 < alpha1_new < self.C:\n",
    "                b_new = b1_new\n",
    "            elif 0 < alpha2_new < self.C:\n",
    "                b_new = b2_new\n",
    "            else:\n",
    "                # 选择中点\n",
    "                b_new = (b1_new + b2_new) / 2\n",
    "\n",
    "            # 更新参数\n",
    "            self.alpha[i1] = alpha1_new\n",
    "            self.alpha[i2] = alpha2_new\n",
    "            self.b = b_new\n",
    "\n",
    "            self.E[i1] = self._E(i1)\n",
    "            self.E[i2] = self._E(i2)\n",
    "        return 'train done!'\n",
    "\n",
    "    def predict(self, data):\n",
    "        r = self.b\n",
    "        for i in range(self.m):\n",
    "            r += self.alpha[i] * self.Y[i] * self.kernel(data, self.X[i])\n",
    "\n",
    "        return 1 if r > 0 else -1\n",
    "\n",
    "    def score(self, X_test, y_test):\n",
    "        right_count = 0\n",
    "        for i in range(len(X_test)):\n",
    "            result = self.predict(X_test[i])\n",
    "            if result == y_test[i]:\n",
    "                right_count += 1\n",
    "        return right_count / len(X_test)\n",
    "\n",
    "    def _weight(self):\n",
    "        # linear model\n",
    "        yx = self.Y.reshape(-1, 1) * self.X\n",
    "        self.w = np.dot(yx.T, self.alpha)\n",
    "        return self.w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "satisfactory-disaster",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.55"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import  train_test_split\n",
    "svm = SVM(max_iter=200)\n",
    "svm.fit(np.array(X_train), np.array(y_train))\n",
    "svm.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aquatic-abortion",
   "metadata": {},
   "source": [
    "感觉比sklearn的默认状态要弱很多。。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
